{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26H1CDZ_86WU"
   },
   "source": [
    "## 字段说明\n",
    "\n",
    "| 字段 | 说明 |\n",
    "| ---- | ---- |\n",
    "| label | 0 唔開心，1 嬲，2 擔心，3 開心 |\n",
    "| review | 數據内容 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JRTxpg09eU6"
   },
   "source": [
    "# Apply Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ek2OIpElsW72"
   },
   "source": [
    "# Fine tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JUfpDE0UdOfd",
    "outputId": "0876d8da-1f7c-477b-fa52-b4146d0eb864"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.21.0-py3-none-any.whl (4.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.7 MB 5.9 MB/s \n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 45.9 MB/s \n",
      "\u001b[?25hCollecting datasets\n",
      "  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
      "\u001b[K     |████████████████████████████████| 365 kB 57.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[K     |████████████████████████████████| 596 kB 8.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
      "\u001b[K     |████████████████████████████████| 101 kB 9.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.6 MB 19.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[K     |████████████████████████████████| 212 kB 51.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
      "Collecting fsspec[http]>=2021.11.1\n",
      "  Downloading fsspec-2022.7.0-py3-none-any.whl (141 kB)\n",
      "\u001b[K     |████████████████████████████████| 141 kB 51.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 40.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "Installing collected packages: urllib3, pyyaml, fsspec, xxhash, tokenizers, responses, huggingface-hub, transformers, sentencepiece, datasets\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "Successfully installed datasets-2.4.0 fsspec-2022.7.0 huggingface-hub-0.8.1 pyyaml-6.0 responses-0.18.0 sentencepiece-0.1.96 tokenizers-0.12.1 transformers-4.21.0 urllib3-1.25.11 xxhash-3.0.0\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pytorch_lightning\n",
      "  Downloading pytorch_lightning-1.6.5-py3-none-any.whl (585 kB)\n",
      "\u001b[K     |████████████████████████████████| 585 kB 39.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (3.17.3)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2022.7.0)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.8.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.1.1)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.64.0)\n",
      "Collecting torchmetrics>=0.4.1\n",
      "  Downloading torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n",
      "\u001b[K     |████████████████████████████████| 419 kB 72.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.12.0+cu113)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (21.3)\n",
      "Collecting pyDeprecate>=0.3.1\n",
      "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.21.6)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.8.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.23.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.9)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1->pytorch_lightning) (1.15.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.35.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.6.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.2.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.4.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (57.4.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.37.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.47.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.9)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (4.12.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (3.8.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2022.6.15)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.2.0)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (0.13.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (6.0.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.7.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.3.0)\n",
      "Installing collected packages: torchmetrics, pyDeprecate, pytorch-lightning\n",
      "Successfully installed pyDeprecate-0.3.2 pytorch-lightning-1.6.5 torchmetrics-0.9.3\n",
      "Mounted at /content/gdrive/\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers sentencepiece datasets\n",
    "!pip install pytorch_lightning\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')\n",
    "\n",
    "import os\n",
    "os.chdir('/content/gdrive/MyDrive/Individual Project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X8CRHKhT-jjo"
   },
   "outputs": [],
   "source": [
    "#package imports \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from transformers import DistilBertTokenizer, AutoTokenizer, AutoModelWithLMHead, DistilBertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "from typing import List\n",
    "import logging\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "from functools import lru_cache\n",
    "from argparse import Namespace\n",
    "from packaging import version\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast as BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rDhsRR3ZBumT"
   },
   "outputs": [],
   "source": [
    "#First, we finetune a T5 transformer model on the Emotion dataset (Saravia et al., 2018). This dataset contains\n",
    "#labelled Twitter posts expressing one of the following emotions: fear, anger, joy, sadness, love, surprise.\n",
    "#We will only use the emotions that we also have in our own dataset, namely fear, anger, joy, sadness.\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('/content/gdrive/MyDrive/Individual Project/Model/LargeDataset/merged_training.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zkemkNMpBujQ"
   },
   "outputs": [],
   "source": [
    "#drop rows classified as 'surprise' or 'love' which we don't need, we only want\n",
    "#sadness, joy, anger and fear\n",
    "\n",
    "data = data.loc[(data.emotions!='surprise') & (data.emotions!='love')]\n",
    "\n",
    "label2int = {\n",
    "  \"sadness\": 1,\n",
    "  \"joy\": 2,\n",
    "  \"anger\": 3,\n",
    "  \"fear\": 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CR2GEu25CL7B",
    "outputId": "530f09c7-a327-4862-9113-68b1ff4e65d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367283"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#after the elimination we are left with 367,283 samples\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DxwmIz19ue2D"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/content/gdrive/MyDrive/Individual Project/Model/LargeDataset/my_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "97zTrSy6CNyq",
    "outputId": "398ec10f-56c9-49d7-e15d-445d78e39c1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd711a91e90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checking the label distribution reveals the dataset is unbalanced\n",
    "data.label.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gaz3oDYDCRNa"
   },
   "outputs": [],
   "source": [
    "#we downsample the majority classes to match the minority class ('fear') and obtain a more equal split of emotion labels\n",
    "\n",
    "#separate the majority and minority classes\n",
    "df_minority  = data[data['emotions']=='fear']\n",
    "df_majority1 = data[data['emotions']=='joy']\n",
    "df_majority2 = data[data['emotions']=='sadness']\n",
    "df_majority3 = data[data['emotions']=='anger']\n",
    "\n",
    "#downsample majority labels equal to the number of samples in the minority class\n",
    "df_majority1 = df_majority1.sample(len(df_minority), random_state=0)\n",
    "df_majority2 = df_majority2.sample(len(df_minority), random_state=0)\n",
    "df_majority3 = df_majority3.sample(len(df_minority), random_state=0)\n",
    "\n",
    "#concat the majority and minority dataframes\n",
    "df_new = pd.concat([df_majority1, df_majority2, df_majority3, df_minority])\n",
    "\n",
    "#shuffle the dataset\n",
    "df_new = df_new.sample(frac=1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "fUkL8a3zCTwZ",
    "outputId": "9827cfb6-bf0e-48f7-b56c-b6a98ffe50c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f81c7794c90>"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check the distribution again, now it's balanced\n",
    "df_new.emotions.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lkakmtTLCVxQ"
   },
   "outputs": [],
   "source": [
    "#get subsample of 20k samples for fine tuning\n",
    "data = df_new.sample(n=20000);\n",
    "\n",
    "#reset index\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Odrq5MCICWgo",
    "outputId": "e3ba9325-8dfc-4fa0-adf4-db3c302d3dd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ner06SfOCdAa"
   },
   "outputs": [],
   "source": [
    "#Generate the text files for train, val, and test datasets in proportion 80:10:10\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "#uncomment the line below to create folder in Drive\n",
    "#!mkdir 'drive/MyDrive/emotion_data'\n",
    "\n",
    "train_path = \"/content/gdrive/MyDrive/Individual Project/Model/LargeDataset/my_train.txt\"\n",
    "test_path = \"/content/gdrive/MyDrive/Individual Project/Model/LargeDataset/my_test.txt\"\n",
    "val_path = \"/content/gdrive/MyDrive/Individual Project/Model/LargeDataset/my_val.txt\"\n",
    "\n",
    "#Create training and validation sets using an 80-20 split\n",
    "input_train, input_val, target_train, target_val = train_test_split(data.text.to_numpy(), \n",
    "                                                                    data.emotions.to_numpy(), \n",
    "                                                                    test_size=0.2)\n",
    "\n",
    "# Split the validataion further to obtain a holdout dataset (for testing) -- split 50:50\n",
    "input_val, input_test, target_val, target_test = train_test_split(input_val, target_val, test_size=0.5)\n",
    "\n",
    "\n",
    "## create a dataframe for each dataset\n",
    "train_dataset = pd.DataFrame(data={\"text\": input_train, \"class\": target_train})\n",
    "val_dataset = pd.DataFrame(data={\"text\": input_val, \"class\": target_val})\n",
    "test_dataset = pd.DataFrame(data={\"text\": input_test, \"class\": target_test})\n",
    "final_dataset = {\"train\": train_dataset, \"val\": val_dataset , \"test\": test_dataset }\n",
    "\n",
    "train_dataset.to_csv(train_path, sep=\";\",header=False, index=False)\n",
    "val_dataset.to_csv(val_path, sep=\";\",header=False, index=False)\n",
    "test_dataset.to_csv(test_path, sep=\";\",header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7LblpllfopBc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z7XXj10FmCLE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# i personally feel it would be too dangerous to get pregnant at this weight;anger\n",
    "\n",
    "read_file = pd.read_csv('/content/gdrive/MyDrive/Individual Project/Model/LargeDataset/my_test.txt',sep=';', header=None)\n",
    "read_file.to_csv (r'/content/gdrive/MyDrive/Individual Project/Model/LargeDataset/my_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ysX4J5pRUVO6"
   },
   "source": [
    "# Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oPN9b-U7-rjx"
   },
   "outputs": [],
   "source": [
    "train_path = \"/content/gdrive/MyDrive/Individual Project/Model/LargeDataset/my_train.txt\"\n",
    "test_path = \"/content/gdrive/MyDrive/Individual Project/Model/LargeDataset/my_test.txt\"\n",
    "val_path = \"/content/gdrive/MyDrive/Individual Project/Model/LargeDataset/my_val.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7xk_qCUm_JEq"
   },
   "outputs": [],
   "source": [
    "#create a dictionary associating each string label to an integer value\n",
    "\n",
    "labels = [ \"唔開心\", \"嬲\", \"擔心\", \"開心\"]\n",
    "label2int = dict(zip(labels, list(range(len(labels)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-AjnAZ3_V04"
   },
   "source": [
    "# Build Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gHEuzNsI_UgI",
    "outputId": "db443491-005c-428b-9e60-3292e8d95f41"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "model_name = \"bert-base-chinese\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 518
    },
    "id": "19qy9RWX_p3p",
    "outputId": "caaced58-eea5-4578-bb6a-34b7ff3546a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                       0     1\n",
      "0                                               我感到暴躁和失望     嬲\n",
      "1                                               我仍然覺得很討厭     嬲\n",
      "2                         我劃過天空 我開始感覺到貿易園里黑暗塔樓的邪惡 psi 氣味     嬲\n",
      "3      我認為大多數遊戲玩家都知道希拉里·克林頓的立場，她強烈認為應該對暴力視頻遊戲對未成年人的影響...     嬲\n",
      "4                我在這裡確實提到了我打算寫一部浪漫喜劇，儘管我已經忘記了我對寫一部感到有些叛逆     嬲\n",
      "...                                                  ...   ...\n",
      "11294                                     我擔心事情永遠不會變得更容易    擔心\n",
      "11295                     我沒有鍛煉我沒有改變任何其他東西，所以我覺得跛腳和沒有生產力   唔開心\n",
      "11296  我喜歡一個女孩表現出自信，但我有一種感覺，這實際上並不能幫助害羞的女孩表現得更自信，這只會讓...    擔心\n",
      "11297                             我相信經常基於過去或你覺得會被愛幾十年的東西    開心\n",
      "11298                                             我真的很孤獨  None\n",
      "\n",
      "[11299 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the separator encoded in utf-8 is > 1 char long, and the 'c' engine does not support such separators; you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-f7f8b994-4cbb-4602-9126-46228a966cc9\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>我感到暴躁和失望</td>\n",
       "      <td>嬲</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>我仍然覺得很討厭</td>\n",
       "      <td>嬲</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>我劃過天空 我開始感覺到貿易園里黑暗塔樓的邪惡 psi 氣味</td>\n",
       "      <td>嬲</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>我認為大多數遊戲玩家都知道希拉里·克林頓的立場，她強烈認為應該對暴力視頻遊戲對未成年人的影響...</td>\n",
       "      <td>嬲</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>我在這裡確實提到了我打算寫一部浪漫喜劇，儘管我已經忘記了我對寫一部感到有些叛逆</td>\n",
       "      <td>嬲</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7f8b994-4cbb-4602-9126-46228a966cc9')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f7f8b994-4cbb-4602-9126-46228a966cc9 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f7f8b994-4cbb-4602-9126-46228a966cc9');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                text class\n",
       "0                                           我感到暴躁和失望     嬲\n",
       "1                                           我仍然覺得很討厭     嬲\n",
       "2                     我劃過天空 我開始感覺到貿易園里黑暗塔樓的邪惡 psi 氣味     嬲\n",
       "3  我認為大多數遊戲玩家都知道希拉里·克林頓的立場，她強烈認為應該對暴力視頻遊戲對未成年人的影響...     嬲\n",
       "4            我在這裡確實提到了我打算寫一部浪漫喜劇，儘管我已經忘記了我對寫一部感到有些叛逆     嬲"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# hi = pd.read_csv(\"/content/gdrive/MyDrive/Individual Project/Model/LargeDataset/my_train.txt\", encoding='utf-8')\n",
    "data = pd.read_csv(\"/content/gdrive/MyDrive/Individual Project/Model/LargeDataset/my_train.txt\", sep=\"；\", header=None, encoding='utf-8')\n",
    "print(data)\n",
    "data.columns = [\"text\",\"class\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n298mCQyKgZE",
    "outputId": "7615a3e3-720d-47f6-f8c9-1bda779ce5c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我一直感覺到情緒，只是沒有真正被它們打擾那麼強烈\n"
     ]
    }
   ],
   "source": [
    "samele_row = data.iloc[5]\n",
    "sample_text = samele_row.text\n",
    "print(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qg1hi3X1Ko3q",
    "outputId": "fa620bcf-ca0c-4718-f1db-19c3d4cc4e19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 512]), torch.Size([1, 512]))"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = tokenizer.encode_plus(\n",
    "    sample_text,\n",
    "    add_special_tokens=True,\n",
    "    max_length=512,\n",
    "    return_token_type_ids=False,\n",
    "    padding=\"max_length\",\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt',\n",
    ")\n",
    "encoding.keys()\n",
    "encoding[\"input_ids\"].shape, encoding[\"attention_mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w594cpw3Kip5",
    "outputId": "a76e840b-b460-4c10-ff9d-5046fe69f1fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '我', '一', '直', '感', '覺', '到', '情', '緒', '，', '只', '是', '沒', '有', '真', '正', '被', '它', '們', '打']\n"
     ]
    }
   ],
   "source": [
    "encoding[\"input_ids\"].squeeze()[:20]\n",
    "print(tokenizer.convert_ids_to_tokens(encoding[\"input_ids\"].squeeze())[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "Ovs0FJZQKsD4",
    "outputId": "d9714fd5-9048-4db0-ecfd-b8842494433d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f81c66d0dd0>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "token_counts = []\n",
    "for _, row in data.iterrows():\n",
    "    token_count = len(tokenizer.encode(\n",
    "        row[\"text\"],\n",
    "        max_length=512,\n",
    "        truncation=True\n",
    "    ))\n",
    "    token_counts.append(token_count)\n",
    "sns.histplot(token_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eaeTrckIK7Aa"
   },
   "outputs": [],
   "source": [
    "MAX_TOKEN_COUNT = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6YdcIjyK1M6"
   },
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6x0vcxOkK0mY"
   },
   "outputs": [],
   "source": [
    "class EmoDataset(Dataset):\n",
    "  def __init__(\n",
    "    self,\n",
    "    path,\n",
    "    tokenizer: BertTokenizer,\n",
    "    max_token_len: int = 100\n",
    "  ):\n",
    "    self.tokenizer = tokenizer\n",
    "    self.data_column = \"text\"\n",
    "    self.class_column = \"class\"\n",
    "    self.data = pd.read_csv(path, sep=\"；\", header=None, names=[self.data_column, self.class_column],\n",
    "                            engine=\"python\")\n",
    "    \n",
    "    self.max_token_len = max_token_len\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "  \n",
    "  def __getitem__(self, index: int):\n",
    "    data_row = self.data.iloc[index]\n",
    "    text = data_row.text\n",
    "    print(data_row)\n",
    "    print(data_row[\"class\"])\n",
    "    labels = label2int[data_row[\"class\"]]\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      text,\n",
    "      add_special_tokens=True,\n",
    "      max_length=self.max_token_len,\n",
    "      return_token_type_ids=False,\n",
    "      padding=\"max_length\",\n",
    "      truncation=True,\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt',\n",
    "    )\n",
    "    return dict(\n",
    "      text=text,\n",
    "      input_ids=encoding[\"input_ids\"].flatten(),\n",
    "      attention_mask=encoding[\"attention_mask\"].flatten(),\n",
    "      labels=torch.tensor(labels)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jimv_t0ULCV5",
    "outputId": "c1c04632-e85d-443d-ed56-c52e03097a56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text     我一直感覺到情緒，只是沒有真正被它們打擾那麼強烈\n",
      "class                         唔開心\n",
      "Name: 5, dtype: object\n",
      "唔開心\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['text', 'input_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = EmoDataset(\n",
    "    train_path,\n",
    "    tokenizer,\n",
    "    max_token_len=100\n",
    ")\n",
    "sample_item = train_dataset[5]\n",
    "sample_item.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BF6Db8xLNURW",
    "outputId": "70419eec-4bc9-4f71-f193-20421a5adfc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_item[\"labels\"]\n",
    "# sample_item[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nPEsn3DQNY0J",
    "outputId": "21c924a1-597b-4909-ca73-286da18351f6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_model = BertModel.from_pretrained(\"bert-base-chinese\")\n",
    "# model = AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lvvpr0vONdpx",
    "outputId": "66f3fde4-8638-48cd-d963-0b37251fee2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text     我感到暴躁和失望\n",
      "class           嬲\n",
      "Name: 0, dtype: object\n",
      "嬲\n",
      "text     我仍然覺得很討厭\n",
      "class           嬲\n",
      "Name: 1, dtype: object\n",
      "嬲\n",
      "text     我劃過天空 我開始感覺到貿易園里黑暗塔樓的邪惡 psi 氣味\n",
      "class                                 嬲\n",
      "Name: 2, dtype: object\n",
      "嬲\n",
      "text     我認為大多數遊戲玩家都知道希拉里·克林頓的立場，她強烈認為應該對暴力視頻遊戲對未成年人的影響...\n",
      "class                                                    嬲\n",
      "Name: 3, dtype: object\n",
      "嬲\n",
      "text     我在這裡確實提到了我打算寫一部浪漫喜劇，儘管我已經忘記了我對寫一部感到有些叛逆\n",
      "class                                          嬲\n",
      "Name: 4, dtype: object\n",
      "嬲\n",
      "text     我一直感覺到情緒，只是沒有真正被它們打擾那麼強烈\n",
      "class                         唔開心\n",
      "Name: 5, dtype: object\n",
      "唔開心\n",
      "text     我很快就睡著了，當親愛的主為我受了這麼多苦時，我覺得我受的苦是多麼少\n",
      "class                                   唔開心\n",
      "Name: 6, dtype: object\n",
      "唔開心\n",
      "text     我有一種感覺，這些可能會在我身上成長為我的最愛，很高興我撿到它們\n",
      "class                                  開心\n",
      "Name: 7, dtype: object\n",
      "開心\n",
      "text     我懷疑由於缺乏國家支持和對環境的參與，他感到無助\n",
      "class                          擔心\n",
      "Name: 8, dtype: object\n",
      "擔心\n",
      "text     我感到無助，有時甚至絕望，我似乎只是順著潮流和現狀走\n",
      "class                            擔心\n",
      "Name: 9, dtype: object\n",
      "擔心\n",
      "text     我能做的就是生氣並感到負擔\n",
      "class              唔開心\n",
      "Name: 10, dtype: object\n",
      "唔開心\n",
      "text     我覺得又一個暴力的白日夢出現了，我敢打賭這與我得到一件聖徒服裝有關\n",
      "class                                    嬲\n",
      "Name: 11, dtype: object\n",
      "嬲\n",
      "text     我感到無助，這很令人不安\n",
      "class             唔開心\n",
      "Name: 12, dtype: object\n",
      "唔開心\n",
      "text     我有機會讓每個人都感到擔心\n",
      "class               擔心\n",
      "Name: 13, dtype: object\n",
      "擔心\n",
      "text     我真的不認為我可以在不感到不安和更不舒服的情況下閱讀這些書\n",
      "class                              唔開心\n",
      "Name: 14, dtype: object\n",
      "唔開心\n",
      "text     看到這一點令人討厭的生物本能在快速回到意識的詛咒之前滲透到人類酒精精神病的迷霧中，我真的感到...\n",
      "class                                                  唔開心\n",
      "Name: 15, dtype: object\n",
      "唔開心\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 100]), torch.Size([16, 100]))"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch = next(iter(DataLoader(train_dataset, batch_size=16)))\n",
    "sample_batch[\"input_ids\"].shape, sample_batch[\"attention_mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5sAvka1lST2f"
   },
   "outputs": [],
   "source": [
    "output = bert_model(sample_batch[\"input_ids\"], sample_batch[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vg5YsRkSSXOv",
    "outputId": "87f368fc-67ae-4ca6-ae42-9b52e244835e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 100, 768]), torch.Size([16, 768]))"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 768 dimension comes from the BERT hidden size\n",
    "output.last_hidden_state.shape, output.pooler_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfOD5_p1SZTg"
   },
   "source": [
    "# Define custom classification model for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Si2HVqMQSYHa"
   },
   "outputs": [],
   "source": [
    "#using Mish activation function \n",
    "#(from https://github.com/digantamisra98/Mish/blob/b5f006660ac0b4c46e2c6958ad0301d7f9c59651/Mish/Torch/mish.py)\n",
    "@torch.jit.script\n",
    "def mish(input):\n",
    "    return input * torch.tanh(F.softplus(input))\n",
    "  \n",
    "class Mish(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return mish(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tMRSSBmJSe1V"
   },
   "outputs": [],
   "source": [
    "#define an EmoClassificationModel class to do the actual fine-tuning\n",
    "\n",
    "class EmoClassificationModel(nn.Module):\n",
    "    def __init__(self, base_model, n_classes, base_model_output_size=768, dropout=0.05):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(base_model_output_size, base_model_output_size),\n",
    "            Mish(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(base_model_output_size, n_classes)\n",
    "        )\n",
    "        \n",
    "        for layer in self.classifier:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                layer.weight.data.normal_(mean=0.0, std=0.02)\n",
    "                if layer.bias is not None:\n",
    "                    layer.bias.data.zero_()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, *args):\n",
    "\n",
    "        hidden_states = self.base_model(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        return self.classifier(hidden_states[0][:, 0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1B5hIWDTSf26"
   },
   "source": [
    "# Prepare lightning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6wLlb1hbSifI"
   },
   "outputs": [],
   "source": [
    "#use PyTorch Lightning for training.\n",
    "#we use PyTorch Lighning for training. Lightning methods are defined here\n",
    "\n",
    "class TrainingModule(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.model = EmoClassificationModel(BertModel.from_pretrained(\"bert-base-chinese\"), len(labels)) #was \"distilroberta-base\"\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "        self.max_token_length = 128\n",
    "        self.loss = nn.CrossEntropyLoss() #cross entropy loss since this is multi-class classification\n",
    "        self.save_hyperparameters(hparams)\n",
    "        self.loss_amount = 0.\n",
    "\n",
    "    def step(self, batch, batch_idx, step_name=\"train\"):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss = self.loss(self.forward(input_ids, attention_mask=attention_mask), labels)\n",
    "        self.loss_amount = loss\n",
    "        loss_key = f\"{step_name}_loss\"\n",
    "        tensorboard_logs = {loss_key: loss}\n",
    "\n",
    "        return { (\"loss\" if step_name == \"train\" else loss_key): loss, 'log': tensorboard_logs,\n",
    "               \"progress_bar\": {loss_key: loss}}\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        return self.model(input_ids, attention_mask)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"train\")\n",
    "\n",
    "    def training_end(self, outputs: List[dict]):\n",
    "        self.loss_amount = torch.stack([x[\"train_loss\"] for x in outputs]).mean()\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"val\")\n",
    "\n",
    "    def validation_end(self, outputs: List[dict]):\n",
    "        loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        return {\"val_loss\": loss}\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"test\")\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.train_path, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.val_path)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.test_path)\n",
    "                \n",
    "    def create_data_loader(self, ds_path: str, shuffle=False):\n",
    "        return DataLoader(\n",
    "                    EmoDataset(ds_path, self.tokenizer, self.max_token_length),\n",
    "                    batch_size=self.hparams.batch_size,\n",
    "                    shuffle=shuffle,\n",
    "        )\n",
    "        \n",
    "    @lru_cache()\n",
    "    def total_steps(self):\n",
    "        return len(self.train_dataloader()) // self.hparams.accumulate_grad_batches * self.hparams.epochs\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.model.parameters(), lr=self.hparams.lr) #we use AdamW as this usually performs well\n",
    "        lr_scheduler = get_linear_schedule_with_warmup(\n",
    "                    optimizer,\n",
    "                    num_warmup_steps=self.hparams.warmup_steps,\n",
    "                    num_training_steps=self.total_steps(),\n",
    "        )\n",
    "        return [optimizer], [{\"scheduler\": lr_scheduler, \"interval\": \"step\"}]\n",
    "   \n",
    "    def save_model(self):\n",
    "        torch.save(self.model.state_dict(), 'BERT_emotion_single_finetuned.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNWHidw-Skjr"
   },
   "source": [
    "# Hyperparameter Search (lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "1284aaf5e8994744b78436a8ff612294",
      "63e4bf0d3a5f48018936a2f912175cf1",
      "8d34363233c44680a81d816e16611363",
      "d73c31610e584723914bc93ad7bbf5f7",
      "7f74a2e36db0487e9af3173a644c9d4c",
      "922c67b9cee34b8baa38b0ecf0b4c9ba",
      "657920101c1f49bab7ca962f60151ca0",
      "90914399f5454250888f739a05ec6198",
      "845fde2e3d63453088b495a9abac2209",
      "ca4838dc7eb047d9bbb219651a68550e",
      "c0c5ff6b44e54de4a5d7bed3f5a5b9b2",
      "1361071936dc4bd8bdaf3b73a27568c7",
      "ae8d3b7a45714ae6a9ca2d097dc03bdd",
      "6756a42fc0db487db0676f5f4530434d",
      "b2d400a62d5647b8aed16ff04fec21d6",
      "f36ff3ba513b4cc0900c770f607a3140",
      "67091feae2d04759ab7dbd72b142cb33",
      "46b9ca3feeaf4fe1a355e0660e2d57ba",
      "5842c46e4ba04f6f8d637b15e1c45436",
      "461da83a1d244fa29c3c6c39135d9bf4",
      "1b1c160b5d43473cb7b726235e74c6f9",
      "3ddcb6647d90494892dd77643edb6fd3"
     ]
    },
    "id": "zj3PPsxjSoap",
    "outputId": "956ef571-e5f6-4483-e3c5-d5c8e524f591"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/callback_connector.py:97: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=50)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "\n",
      "  | Name  | Type                   | Params\n",
      "-------------------------------------------------\n",
      "0 | model | EmoClassificationModel | 102 M \n",
      "1 | loss  | CrossEntropyLoss       | 0     \n",
      "-------------------------------------------------\n",
      "102 M     Trainable params\n",
      "0         Non-trainable params\n",
      "102 M     Total params\n",
      "411.445   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1284aaf5e8994744b78436a8ff612294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text     我從無助到強大\n",
      "class         擔心\n",
      "Name: 0, dtype: object\n",
      "擔心\n",
      "text     我真的需要發洩我的感情，我現在很生氣\n",
      "class                     嬲\n",
      "Name: 1, dtype: object\n",
      "嬲\n",
      "text     我覺得有點小氣\n",
      "class          嬲\n",
      "Name: 2, dtype: object\n",
      "嬲\n",
      "text     我終於進了浴室，但我無法做任何事情來讓自己感覺更好相信我，我什至嘗試嘔吐\n",
      "class                                      開心\n",
      "Name: 3, dtype: object\n",
      "開心\n",
      "text     我感覺就像一堆情感瓦礫\n",
      "class            唔開心\n",
      "Name: 4, dtype: object\n",
      "唔開心\n",
      "text     我真的厭倦了人們告訴我這不是故意的，因為這讓我覺得過去的一年都不重要或沒有任何意義\n",
      "class                                           開心\n",
      "Name: 5, dtype: object\n",
      "開心\n",
      "text     我為一個懷孕的朋友感到焦慮 我意識到我還沒有準備好認真考慮生另一個孩子\n",
      "class                                     擔心\n",
      "Name: 6, dtype: object\n",
      "擔心\n",
      "text     當我的伴侶想要親近時我感到不舒服\n",
      "class                  擔心\n",
      "Name: 7, dtype: object\n",
      "擔心\n",
      "text     我也注意到我開始感到非常沮喪\n",
      "class               唔開心\n",
      "Name: 8, dtype: object\n",
      "唔開心\n",
      "text     我並不特別覺得有必要為此找藉口，但我確實有點想知道這些樂隊被我的同齡人如此討厭，因為我認為他...\n",
      "class                                                    嬲\n",
      "Name: 9, dtype: object\n",
      "嬲\n",
      "text     我不喜歡線條像大提琴一樣圓潤的歌曲\n",
      "class                   開心\n",
      "Name: 10, dtype: object\n",
      "開心\n",
      "text     自從我安裝了這個壞男孩後，這些天我感覺有點叛逆\n",
      "class                          嬲\n",
      "Name: 11, dtype: object\n",
      "嬲\n",
      "text     我回家並沒有太著急，我有一點迴旋的餘地，可以讓自己吃一頓非常棒的午餐，並在那段時間完成一些工作\n",
      "class                                                  嬲\n",
      "Name: 12, dtype: object\n",
      "嬲\n",
      "text     我一直對生活中的事情如何整理感到有些苦惱\n",
      "class                      擔心\n",
      "Name: 13, dtype: object\n",
      "擔心\n",
      "text     我現在感覺很匆忙\n",
      "class           嬲\n",
      "Name: 14, dtype: object\n",
      "嬲\n",
      "text     我告訴過你，我覺得自己像一個被你俘虜的野蠻人，儘管我覺得我愛你，喜歡和你建立關係，但我必須出...\n",
      "class                                                    嬲\n",
      "Name: 15, dtype: object\n",
      "嬲\n",
      "text     我坐在這裡感覺有點善良\n",
      "class             開心\n",
      "Name: 16, dtype: object\n",
      "開心\n",
      "text     當我感到如此壓抑時，我應該變得堅強\n",
      "class                   擔心\n",
      "Name: 17, dtype: object\n",
      "擔心\n",
      "text     我在學業上並不擔心她，但她的成熟度或與其他人的交往總是有點延遲，我討厭看到她努力結交朋友並感...\n",
      "class                                                   開心\n",
      "Name: 18, dtype: object\n",
      "開心\n",
      "text     我知道所有支持自己和家人的人都不會同情，但我感到擔心和唔開心\n",
      "class                                擔心\n",
      "Name: 19, dtype: object\n",
      "擔心\n",
      "text     我理解，但我覺得我討厭我的朋友\n",
      "class                  嬲\n",
      "Name: 20, dtype: object\n",
      "嬲\n",
      "text     我現在感到不滿意可能是因為我今天花太多時間在電腦上編輯我過去一個月拍攝的無數照片而沒有足夠的...\n",
      "class                                                    嬲\n",
      "Name: 21, dtype: object\n",
      "嬲\n",
      "text     我對我的信的質量感到非常非常偏執\n",
      "class                  擔心\n",
      "Name: 22, dtype: object\n",
      "擔心\n",
      "text     我為自己感到難過，因為我沒有信心面對自己的問題\n",
      "class                        唔開心\n",
      "Name: 23, dtype: object\n",
      "唔開心\n",
      "text     我習慣於在正常人中感到不舒服，儘管直到我四十多歲才診斷出我的獨特性\n",
      "class                                   擔心\n",
      "Name: 24, dtype: object\n",
      "擔心\n",
      "text     我覺得如果我在那個島上，我會被他嚇到\n",
      "class                    擔心\n",
      "Name: 25, dtype: object\n",
      "擔心\n",
      "text     我感到很沮喪，即使我知道自從我感覺良好以來，在那一分鐘內沒有任何有形的改變，但我的眼睛裡有淚...\n",
      "class                                                  唔開心\n",
      "Name: 26, dtype: object\n",
      "唔開心\n",
      "text     我因為想要更多的時間和她在一起而感到自私\n",
      "class                       嬲\n",
      "Name: 27, dtype: object\n",
      "嬲\n",
      "text     我覺得好像我錯過了機會，並且必須等待很長時間才能再次獲得機會\n",
      "class                               唔開心\n",
      "Name: 28, dtype: object\n",
      "唔開心\n",
      "text     當我參加大學一年級考試並且在p考試中犯了很多錯誤時，我擔心不及格而無法上醫學院\n",
      "class                                         擔心\n",
      "Name: 29, dtype: object\n",
      "擔心\n",
      "text     我去了醫院 我在床上醒來時感到最不尋常的極度寒冷 我覺得這不是普通的感冒，但我能感覺到我的骨...\n",
      "class                                                   開心\n",
      "Name: 30, dtype: object\n",
      "開心\n",
      "text     我仍然對他很生氣，感覺這段關係可能注定要失敗\n",
      "class                       唔開心\n",
      "Name: 31, dtype: object\n",
      "唔開心\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1361071936dc4bd8bdaf3b73a27568c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text     我也只是覺得我有很多愚蠢的差事，我不想騰出時間，但重要性會增加\n",
      "class                                唔開心\n",
      "Name: 165, dtype: object\n",
      "唔開心\n",
      "text     我只是在做一個快速的帖子，因為它太晚了，而且我因為懷孕三個月的孕吐而感覺不好\n",
      "class                                        開心\n",
      "Name: 8563, dtype: object\n",
      "開心\n",
      "text     我喜歡知道每當我覺得它們看起來有點臟時，我就可以把它們取下來清潔它們\n",
      "class                                   唔開心\n",
      "Name: 1281, dtype: object\n",
      "唔開心\n",
      "text     我很榮幸能獲得這個獎項，因為我覺得這是朝著這個令人難以置信的講故事傳統邁出的又一步\n",
      "class                                           開心\n",
      "Name: 6812, dtype: object\n",
      "開心\n",
      "text     當我沒有分心時，我無法阻止我獨自一人時的焦慮\n",
      "class                       唔開心\n",
      "Name: 4114, dtype: object\n",
      "唔開心\n",
      "text     我開始考慮重新寫博客，但我有點不知所措\n",
      "class                     擔心\n",
      "Name: 1370, dtype: object\n",
      "擔心\n",
      "text     走在外面我感覺更有信心了\n",
      "class              開心\n",
      "Name: 8641, dtype: object\n",
      "開心\n",
      "text     我走了，我只是覺得自己是城裡最受歡迎的女孩\n",
      "class                       開心\n",
      "Name: 4411, dtype: object\n",
      "開心\n",
      "text     反正我覺得你很反常我會毫不猶豫地阻止你\n",
      "class                    唔開心\n",
      "Name: 14286, dtype: object\n",
      "唔開心\n",
      "text     我覺得教室非常危險\n",
      "class            嬲\n",
      "Name: 5422, dtype: object\n",
      "嬲\n",
      "text     當我看到它弄髒他們的牛仔褲時，我感到一種惡意的滿足感\n",
      "class                             嬲\n",
      "Name: 2931, dtype: object\n",
      "嬲\n",
      "text     我是一個勤奮的博主，我會檢查所有最好的，看看這些曲子是否在某個地方可用，但我今天感覺有點厭倦...\n",
      "class                                                  唔開心\n",
      "Name: 10634, dtype: object\n",
      "唔開心\n",
      "text     我帶著對猶太教的自豪感說這一切，同時對那些因無法結婚而感到冒犯的同性戀者感到悲哀\n",
      "class                                           嬲\n",
      "Name: 8663, dtype: object\n",
      "嬲\n",
      "text     我相信感受二元性靈性痛苦和成長提供了幸福簡單的開心和滿足感的表現\n",
      "class                                 唔開心\n",
      "Name: 15793, dtype: object\n",
      "唔開心\n",
      "text     我開始了這種不讀聖經不祈禱的狼吞虎咽，即使有一首基督教歌曲會響起\n",
      "class                                None\n",
      "Name: 13043, dtype: object\n",
      "None\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-243-6d005ed797a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     trainer = pl.Trainer(gpus=1, max_epochs=hparams_tmp.epochs, progress_bar_refresh_rate=50,\n\u001b[1;32m     19\u001b[0m                     accumulate_grad_batches=hparams_tmp.accumulate_grad_batches)\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_tmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_amount\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         self._call_and_handle_interrupt(\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m         )\n\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m         \u001b[0;31m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_provided\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m         )\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1234\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__}: trainer tearing down\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1353\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_EVALUATE_OUTPUT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    264\u001b[0m         )\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoaderIterDataFetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mbatch_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetching_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\u001b[0m in \u001b[0;36mfetching_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;31m# this will run only when no pre-fetching was done.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m                 \u001b[0;31m# consume the batch we just fetched\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\u001b[0m in \u001b[0;36m_fetch_next_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fetch_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mstart_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_fetch_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetched\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch_batches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/supporters.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0ma\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0mof\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \"\"\"\n\u001b[0;32m--> 558\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/supporters.py\u001b[0m in \u001b[0;36mrequest_next_batch\u001b[0;34m(loader_iters)\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0mof\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \"\"\"\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mapply_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/apply_func.py\u001b[0m in \u001b[0;36mapply_to_collection\u001b[0;34m(data, dtype, function, wrong_dtype, include_none, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# Breaking condition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwrong_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrong_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0melem_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    650\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-233-38ca0f48cf08>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel2int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     encoding = self.tokenizer.encode_plus(\n\u001b[1;32m     26\u001b[0m       \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "lrs = np.logspace(-1,-7,10)\n",
    "losses = [0] * len(lrs)\n",
    "for i in range(len(lrs)):\n",
    "    hparams_tmp = Namespace(\n",
    "    train_path=train_path,\n",
    "    val_path=val_path,\n",
    "    test_path=test_path,\n",
    "    batch_size=16,\n",
    "    warmup_steps=100,\n",
    "    epochs=1,\n",
    "    lr=lrs[i],\n",
    "    accumulate_grad_batches=1\n",
    "    )\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    module_tmp = TrainingModule(hparams_tmp)\n",
    "    trainer = pl.Trainer(gpus=1, max_epochs=hparams_tmp.epochs, progress_bar_refresh_rate=50,\n",
    "                    accumulate_grad_batches=hparams_tmp.accumulate_grad_batches)\n",
    "    trainer.fit(module_tmp)\n",
    "    losses[i] = module_tmp.loss_amount.cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9_cFuB30Spun"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "line, = ax.plot(lrs, losses, color='b')\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel(\"learning rates\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4uEN0d5mXjvc"
   },
   "outputs": [],
   "source": [
    "pd.to_csv(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Vwdza-9_G_g"
   },
   "source": [
    "# Ori\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 872
    },
    "id": "L2vu3qP4Bh2m",
    "outputId": "ace58828-4f02-4d10-9e38-b0524285758b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.20.1\n",
      "Uninstalling transformers-4.20.1:\n",
      "  Would remove:\n",
      "    /usr/local/bin/transformers-cli\n",
      "    /usr/local/lib/python3.7/dist-packages/transformers-4.20.1.dist-info/*\n",
      "    /usr/local/lib/python3.7/dist-packages/transformers/*\n",
      "Proceed (y/n)? y\n",
      "  Successfully uninstalled transformers-4.20.1\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers==4.18.0\n",
      "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 32.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (6.0)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001b[K     |████████████████████████████████| 880 kB 60.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (1.21.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (0.8.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (4.12.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (2.23.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (0.12.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (3.7.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (2022.6.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (4.64.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.18.0) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.18.0) (3.8.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0) (2022.6.15)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.18.0) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.18.0) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.18.0) (1.1.0)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=47e10a42df8f0131f5b8034cd04b905b52993b89028bb16ef88473e1c6c3db39\n",
      "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.53 transformers-4.18.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "transformers"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip uninstall transformers\n",
    "!pip install transformers==4.18.0y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 603
    },
    "id": "8Vl6lQL-MS35",
    "outputId": "c95b8e43-eed8-43a2-cef6-67b94ca30286"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3797' max='15000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3797/15000 14:16 < 42:06, 4.43 it/s, Epoch 2.53/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.453800</td>\n",
       "      <td>0.414961</td>\n",
       "      <td>0.869000</td>\n",
       "      <td>0.869000</td>\n",
       "      <td>0.869000</td>\n",
       "      <td>0.869000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.355500</td>\n",
       "      <td>0.389060</td>\n",
       "      <td>0.877333</td>\n",
       "      <td>0.877333</td>\n",
       "      <td>0.877333</td>\n",
       "      <td>0.877333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15000' max='15000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15000/15000 57:13, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.453800</td>\n",
       "      <td>0.414961</td>\n",
       "      <td>0.869000</td>\n",
       "      <td>0.869000</td>\n",
       "      <td>0.869000</td>\n",
       "      <td>0.869000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.355500</td>\n",
       "      <td>0.389060</td>\n",
       "      <td>0.877333</td>\n",
       "      <td>0.877333</td>\n",
       "      <td>0.877333</td>\n",
       "      <td>0.877333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.273300</td>\n",
       "      <td>0.482273</td>\n",
       "      <td>0.869333</td>\n",
       "      <td>0.869333</td>\n",
       "      <td>0.869333</td>\n",
       "      <td>0.869333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.235900</td>\n",
       "      <td>0.559721</td>\n",
       "      <td>0.873000</td>\n",
       "      <td>0.873000</td>\n",
       "      <td>0.873000</td>\n",
       "      <td>0.873000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.197500</td>\n",
       "      <td>0.598345</td>\n",
       "      <td>0.875667</td>\n",
       "      <td>0.875667</td>\n",
       "      <td>0.875667</td>\n",
       "      <td>0.875667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.171400</td>\n",
       "      <td>0.624162</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>0.882000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.118400</td>\n",
       "      <td>0.715196</td>\n",
       "      <td>0.877333</td>\n",
       "      <td>0.877333</td>\n",
       "      <td>0.877333</td>\n",
       "      <td>0.877333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.085600</td>\n",
       "      <td>0.747963</td>\n",
       "      <td>0.878333</td>\n",
       "      <td>0.878333</td>\n",
       "      <td>0.878333</td>\n",
       "      <td>0.878333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.075200</td>\n",
       "      <td>0.805825</td>\n",
       "      <td>0.875333</td>\n",
       "      <td>0.875333</td>\n",
       "      <td>0.875333</td>\n",
       "      <td>0.875333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.050600</td>\n",
       "      <td>0.804090</td>\n",
       "      <td>0.878333</td>\n",
       "      <td>0.878333</td>\n",
       "      <td>0.878333</td>\n",
       "      <td>0.878333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15000, training_loss=0.21559882532755534, metrics={'train_runtime': 3434.1413, 'train_samples_per_second': 43.679, 'train_steps_per_second': 4.368, 'total_flos': 8402232430800000.0, 'train_loss': 0.21559882532755534, 'epoch': 10.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import torch\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "\n",
    "# Read data\n",
    "data = pd.read_csv(\"/content/gdrive/MyDrive/Individual Project/Model/LargeDataset/my_dataset.csv\")\n",
    "\n",
    "# Define pretrained tokenizer and model\n",
    "# model_name = \"/content/gdrive/MyDrive/Individual Project/Model/Final Model\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-chinese\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-chinese\", num_labels=4)\n",
    "\n",
    "# ----- 1. Preprocess data -----#\n",
    "# Preprocess data\n",
    "X = list(data[\"content\"])\n",
    "y = list(data[\"label\"])\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1 - train_ratio, random_state=0)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state=0) \n",
    "\n",
    "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
    "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)\n",
    "X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=512)\n",
    "\n",
    "\n",
    "# Create torch dataset\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "train_dataset = Dataset(X_train_tokenized, y_train)\n",
    "val_dataset = Dataset(X_val_tokenized, y_val)\n",
    "test_dataset=Dataset(X_test_tokenized, y_test)\n",
    "\n",
    "# ----- 2. Fine-tune pretrained model -----#\n",
    "# Define Trainer parameters\n",
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred, average='micro')\n",
    "    precision = precision_score(y_true=labels, y_pred=pred, average='micro')\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred, average='micro')\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "# Define Trainer\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"/content/gdrive/MyDrive/Individual Project/Model\",\n",
    "    num_train_epochs=10,\n",
    "    learning_rate =1e-5,\n",
    "    adam_epsilon=1e-06, \n",
    "    per_device_train_batch_size=10,\n",
    "    per_device_eval_batch_size=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy='epoch',\n",
    "    disable_tqdm=False,\n",
    "    eval_steps=500,\n",
    "    logging_steps=500,\n",
    "    log_level='error',\n",
    "    save_total_limit = 2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='accuracy',\n",
    "    overwrite_output_dir=False,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    # callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "    # callbacks=checkpoint_callback,\n",
    ")\n",
    "\n",
    "# Train pre-trained model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batcpJ8Ou-z8"
   },
   "outputs": [],
   "source": [
    "trainer.save_model(\"/content/gdrive/MyDrive/Individual Project/Model/LargeDataset/BERTLarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176,
     "referenced_widgets": [
      "69c0ffad48954051b91a7f4e4537912c",
      "f14081e50e2a4f16b1aad53f2aec914f",
      "20da26b00f3e48ed94e9ce5b1eff73f8",
      "2dccde0abc7e46bf986404dfd525e2fe",
      "f15745dcceda4b49a5c6d62884b14689",
      "f8835fec360843afaf4eb251cf270ca4",
      "7a5e2b2a495f4cb29e520b0fa69418c6",
      "32edf7574cdf4c8090d5407b7df613b0",
      "80fa4d988c374871a1ddb2ff3dff4634",
      "60d48de1dca14a679ca8f3bf6c88a6bd",
      "f6bded58b375481ab089661243779673"
     ]
    },
    "id": "HDE9M1S-7DtK",
    "outputId": "bb3f1fa8-71f5-440a-b4da-b28587059a7e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c0ffad48954051b91a7f4e4537912c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='222' max='222' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [222/222 00:15, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.678463</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.802721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=222, training_loss=0.07656740068315386, metrics={'train_runtime': 16.0402, 'train_samples_per_second': 138.028, 'train_steps_per_second': 13.84, 'total_flos': 65990671003296.0, 'train_loss': 0.07656740068315386, 'epoch': 3.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(resume_from_checkpoint='/content/gdrive/MyDrive/Individual Project/Model/checkpoint-148')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "id": "R4FWrG1TW6rz",
    "outputId": "3d238d70-909b-4730-ea6f-da9a555982ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'epoch': 20.0,\n",
       " 'eval_accuracy': 0.2925170068027211,\n",
       " 'eval_f1': 0.2925170068027211,\n",
       " 'eval_loss': 1.4193344116210938,\n",
       " 'eval_precision': 0.2925170068027211,\n",
       " 'eval_recall': 0.2925170068027211,\n",
       " 'eval_runtime': 0.4829,\n",
       " 'eval_samples_per_second': 304.41,\n",
       " 'eval_steps_per_second': 31.062}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "id": "5sdLvCmP989-",
    "outputId": "276869de-4879-4215-f90f-aeceb4d8abf1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_accuracy': 0.21212121212121213,\n",
       " 'test_f1': 0.21212121212121215,\n",
       " 'test_loss': 1.4364556074142456,\n",
       " 'test_precision': 0.21212121212121213,\n",
       " 'test_recall': 0.21212121212121213,\n",
       " 'test_runtime': 0.3287,\n",
       " 'test_samples_per_second': 301.185,\n",
       " 'test_steps_per_second': 30.423}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.predict(test_dataset=test_dataset).metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OXSkvmos6Ogl"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"/content/gdrive/MyDrive/Individual Project/Model/Fine-tuned/best_bert-base-chinese\", local_files_only=True)\n",
    "trainer.model = model.cuda()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tug03biYOds0",
    "outputId": "12ef2469-ac49-4300-d5bc-de271139f6cf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 8\n"
     ]
    }
   ],
   "source": [
    "# ----- 3. Predict -----#\n",
    "# Load test data\n",
    "# test_data = pd.read_csv(\"/content/gdrive/MyDrive/Individual Project/廣東話情感句子2.0.csv\")\n",
    "# X_test = list(test_data[\"content\"])\n",
    "# X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Create torch dataset\n",
    "test_dataset = test_dataset\n",
    "\n",
    "# Load trained model\n",
    "model_path = \"/content/gdrive/MyDrive/Individual Project/Model/LargeDataset/BERTLarge\"\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Define test trainer\n",
    "test_trainer = Trainer(model)\n",
    "\n",
    "# Make prediction\n",
    "raw_pred, _, _ = test_trainer.predict(test_dataset)\n",
    "\n",
    "# Preprocess raw predictions\n",
    "y_pred = np.argmax(raw_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8_jKirR0SpX1"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bRs9AX4zSJ4z",
    "outputId": "5412ba72-720b-45fa-9c32-639f2c47495f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8648    0.8717    0.8683       499\n",
      "           1     0.9147    0.8298    0.8702       517\n",
      "           2     0.8618    0.9158    0.8880       463\n",
      "           3     0.8937    0.9194    0.9063       521\n",
      "\n",
      "    accuracy                         0.8835      2000\n",
      "   macro avg     0.8837    0.8842    0.8832      2000\n",
      "weighted avg     0.8845    0.8835    0.8832      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DoDCKDYpsC0R"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BertLargeDataset.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1284aaf5e8994744b78436a8ff612294": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_63e4bf0d3a5f48018936a2f912175cf1",
       "IPY_MODEL_8d34363233c44680a81d816e16611363",
       "IPY_MODEL_d73c31610e584723914bc93ad7bbf5f7"
      ],
      "layout": "IPY_MODEL_7f74a2e36db0487e9af3173a644c9d4c"
     }
    },
    "1361071936dc4bd8bdaf3b73a27568c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ae8d3b7a45714ae6a9ca2d097dc03bdd",
       "IPY_MODEL_6756a42fc0db487db0676f5f4530434d",
       "IPY_MODEL_b2d400a62d5647b8aed16ff04fec21d6"
      ],
      "layout": "IPY_MODEL_f36ff3ba513b4cc0900c770f607a3140"
     }
    },
    "1b1c160b5d43473cb7b726235e74c6f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20da26b00f3e48ed94e9ce5b1eff73f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32edf7574cdf4c8090d5407b7df613b0",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_80fa4d988c374871a1ddb2ff3dff4634",
      "value": 0
     }
    },
    "2dccde0abc7e46bf986404dfd525e2fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60d48de1dca14a679ca8f3bf6c88a6bd",
      "placeholder": "​",
      "style": "IPY_MODEL_f6bded58b375481ab089661243779673",
      "value": " 0/0 [00:00&lt;?, ?it/s]"
     }
    },
    "32edf7574cdf4c8090d5407b7df613b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "3ddcb6647d90494892dd77643edb6fd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "461da83a1d244fa29c3c6c39135d9bf4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "46b9ca3feeaf4fe1a355e0660e2d57ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5842c46e4ba04f6f8d637b15e1c45436": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60d48de1dca14a679ca8f3bf6c88a6bd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63e4bf0d3a5f48018936a2f912175cf1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_922c67b9cee34b8baa38b0ecf0b4c9ba",
      "placeholder": "​",
      "style": "IPY_MODEL_657920101c1f49bab7ca962f60151ca0",
      "value": "Sanity Checking DataLoader 0: 100%"
     }
    },
    "657920101c1f49bab7ca962f60151ca0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "67091feae2d04759ab7dbd72b142cb33": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6756a42fc0db487db0676f5f4530434d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5842c46e4ba04f6f8d637b15e1c45436",
      "max": 1125,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_461da83a1d244fa29c3c6c39135d9bf4",
      "value": 0
     }
    },
    "69c0ffad48954051b91a7f4e4537912c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f14081e50e2a4f16b1aad53f2aec914f",
       "IPY_MODEL_20da26b00f3e48ed94e9ce5b1eff73f8",
       "IPY_MODEL_2dccde0abc7e46bf986404dfd525e2fe"
      ],
      "layout": "IPY_MODEL_f15745dcceda4b49a5c6d62884b14689"
     }
    },
    "7a5e2b2a495f4cb29e520b0fa69418c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7f74a2e36db0487e9af3173a644c9d4c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "80fa4d988c374871a1ddb2ff3dff4634": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "845fde2e3d63453088b495a9abac2209": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8d34363233c44680a81d816e16611363": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_90914399f5454250888f739a05ec6198",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_845fde2e3d63453088b495a9abac2209",
      "value": 2
     }
    },
    "90914399f5454250888f739a05ec6198": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "922c67b9cee34b8baa38b0ecf0b4c9ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae8d3b7a45714ae6a9ca2d097dc03bdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67091feae2d04759ab7dbd72b142cb33",
      "placeholder": "​",
      "style": "IPY_MODEL_46b9ca3feeaf4fe1a355e0660e2d57ba",
      "value": "Epoch 0:   0%"
     }
    },
    "b2d400a62d5647b8aed16ff04fec21d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b1c160b5d43473cb7b726235e74c6f9",
      "placeholder": "​",
      "style": "IPY_MODEL_3ddcb6647d90494892dd77643edb6fd3",
      "value": " 0/1125 [00:00&lt;?, ?it/s]"
     }
    },
    "c0c5ff6b44e54de4a5d7bed3f5a5b9b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ca4838dc7eb047d9bbb219651a68550e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d73c31610e584723914bc93ad7bbf5f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca4838dc7eb047d9bbb219651a68550e",
      "placeholder": "​",
      "style": "IPY_MODEL_c0c5ff6b44e54de4a5d7bed3f5a5b9b2",
      "value": " 2/2 [00:00&lt;00:00, 25.79it/s]"
     }
    },
    "f14081e50e2a4f16b1aad53f2aec914f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8835fec360843afaf4eb251cf270ca4",
      "placeholder": "​",
      "style": "IPY_MODEL_7a5e2b2a495f4cb29e520b0fa69418c6",
      "value": "Skipping the first batches: "
     }
    },
    "f15745dcceda4b49a5c6d62884b14689": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f36ff3ba513b4cc0900c770f607a3140": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "f6bded58b375481ab089661243779673": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f8835fec360843afaf4eb251cf270ca4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
